from deepchem.models.tensorgraph.layers import GraphPool, GraphGather
from deepchem.models.tensorgraph.layers import Dense, L2Loss, WeightedError, Stack
from deepchem.models.tensorgraph.layers import Label, Weights
import numpy as np
import tensorflow as tf
import os 
import numpy as np
import numpy.random as random
import scipy as sp
import pandas as pd
from pandas import Series, DataFrame
from sklearn.model_selection import train_test_split

os.chdir('D:/kenkyu/inputdata')
os.getcwd()

num_epochs = 50
batch_size = 200
pad_batches = True

tg = tensorgraph(batch_size=batch_size,learning_rate=0.0005,use_queue=False)
prediction_tasks = ['V']

def read_data(input_file_path="deepchem.csv"):
    featurizer = dc.feat.ConvMolFeaturizer()
    loader = dc.data.CSVLoader(tasks=prediction_tasks, smiles_field="Smiles", featurizer=featurizer)
    dataset = loader.featurize(input_file_path, shard_size=8192)
    # Initialize transformers
    transformer = dc.trans.NormalizationTransformer(transform_w=True, dataset=dataset)
    print("About to transform data")
    dataset = transformer.transform(dataset)
    #Randomly split into training and testing : 80-20 split.
    splitter = dc.splits.splitters.RandomSplitter()
    trainset,testset = splitter.train_test_split(dataset,frac_train=0.8)
    return trainset,testset
