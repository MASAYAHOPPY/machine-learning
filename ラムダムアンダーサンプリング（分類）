from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import SelectFromModel
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from imblearn.pipeline import Pipeline 
from imblearn.under_sampling import RandomUnderSampler

y_train.value_counts()
strategy = {"1":59748, "2":8382, "3":578, "4":805, "6":169, "a":20, "b":3686, "c":1088, "d":240, "e":6, "m":141, "n":1637}
select = SelectFromModel(RandomForestClassifier(max_depth=30, n_estimators=30, random_state=42))
scaler = StandardScaler()
clf = RandomForestClassifier(max_depth=30, n_estimators=30, random_state=42)
rus = RandomUnderSampler(random_state=0, sampling_strategy = strategy)

estimator = [
    ('rus', rus),
    ('select', select),
    ('scaler', scaler),
    ('clf', clf)
]
pipe_rus = Pipeline(estimator)
pipe_rus.fit(X_train, y_train)

y_pred = pipe_rus.predict(X_test)
from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))

#pipeによるモデルの作製
#scaler：特徴量の標準化
#select=重要度の高い記述子を残す
#rus=アンダーサンプリング
#混同行列
#sttategyは分類の個数を入れる。sklearn更新の必要性あり、基本的にはclfにモデルセットすればOK

ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー
＃（※少数サンプル数＊X倍）サブの方法
positive_count_train = y_train.value_counts()[1]
strategy = {"1":positive_count_train, "2":positive_count_train*10, "3":positive_count_train*10, "4":positive_count_train*10, "6":positive_count_train*10, "a":positive_count_train*10, "b":positive_count_train*10, "c":positive_count_train*10, "d":positive_count_train*10, "e":positive_count_train*10, "m":positive_count_train*10, "n":positive_count_train*10}
#トレーニング数
#トレーニング数の中で、””に書かれた文字が該当する数
ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー
#　モデルトレーニング
X_resampled, y_resampled = rus.fit_resample(X_train, y_train)
y_resampled.value_counts()
#　[]に引数を指定して、一つ一つの答えの文字列の数を数えたのちに、starategyに代入
positive_count_train = y_train.value_counts()["1"]
print(positive_count_train)
